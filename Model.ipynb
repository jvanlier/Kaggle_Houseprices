{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning for Kaggle House Price prediction\n",
    "==================\n",
    "\n",
    "This notebook contains data preprocessing, machine learning and finally an ensemble to create the prediction.\n",
    "\n",
    "See [my blog](http://jorivanlier.nl/blog/2017/08/26/kaggle-house-price-prediction.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "\n",
    "from preprocess import prep_data\n",
    "from utils import rmsle, rmsle_sk, create_submission, create_submission_from_ensemble, \\\n",
    "                  sqrt_transform_helper, log_transform_helper, ihs_transform_helper\n",
    "from crossval import calc_kfold_score, gridcv\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COL_Y = 'SalePrice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 2919 n_cols:  80\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv', index_col='Id')\n",
    "df_test = pd.read_csv('data/test.csv', index_col='Id')\n",
    "df_comb = pd.concat((df_train, df_test))\n",
    "df_comb = df_comb.sample(frac=1)  # Shuffle - just in case\n",
    "\n",
    "print(\"n:\", len(df_comb), \"n_cols: \", len(df_comb.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some mandatory conversions\n",
    "\n",
    "These conversion must be performed. Reasons include data that's read incorrectly, has too many missing values for our imputation algorithm to handle, or other code relies on it having been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The other code assumes log transform on the output variable so it's kind of non-optional:\n",
    "df_comb[COL_Y] = np.log(df_comb[COL_Y].values)\n",
    "\n",
    "# Missing values for the following columns indicate that the property doesn't have it \n",
    "# (according to the Kaggle docs):\n",
    "cols_nan_means_missing = ['Alley', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "                          'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "for col in cols_nan_means_missing:\n",
    "    df_comb.loc[df_comb[col].isnull(), col] = 'N/A'\n",
    "\n",
    "# Basement is a bit trickier because sometimes only one of the fields is missing, but that doesn't mean that\n",
    "# there is no basement.\n",
    "bsmt_cols = [c for c in df_comb.columns if 'Bsmt' in c]\n",
    "bsmt_cols_num = [c for c in bsmt_cols if df_comb[c].dtype != 'object']\n",
    "bsmt_cols_cat = set(bsmt_cols) - set(bsmt_cols_num)\n",
    "df_comb.loc[(df_comb['BsmtQual'].isnull()) & (df_comb['BsmtCond'].isnull()), bsmt_cols_cat] = 'NoBsmt'\n",
    "df_comb.loc[(df_comb['BsmtCond'] == 'NoBsmt'), bsmt_cols_num] = 0\n",
    "\n",
    "# Garage as well:\n",
    "gar_cols = {c for c in df_comb.columns if 'garage' in c.lower()}\n",
    "gar_cols_num = {c for c in gar_cols if df_comb[c].dtype != 'object'}\n",
    "gar_cols_cat = gar_cols - gar_cols_num\n",
    "# I don't really know what's best for missing values in GarageYrBlt. Will let KNN impute something:\n",
    "gar_cols_num.remove('GarageYrBlt')  \n",
    "cond_nogar = (df_comb['GarageArea'] == 0) | (df_comb['GarageArea'].isnull())\n",
    "df_comb.loc[cond_nogar, gar_cols_cat] = 'NoGarage'\n",
    "df_comb.loc[cond_nogar, gar_cols_num] = 0\n",
    "\n",
    "# Masonry veneer, assuming that a property doesn't have it if both fields are null.\n",
    "df_comb.loc[(df_comb['MasVnrArea'].isnull()) & (df_comb['MasVnrType'].isnull()), \n",
    "            ['MasVnrType', 'MasVnrArea']] = ['None', 0]\n",
    "\n",
    "# Too many missing values or not enough distinct values to be useful:\n",
    "# (Yes, this includes columns where I put N/A earlier, I might change my mind about dropping them and \n",
    "#  will want to keep the N/A in that case).\n",
    "df_comb = df_comb.drop(['Alley', 'MiscFeature', 'Utilities', 'Electrical', 'PoolArea', 'PoolQC'], axis=1)  \n",
    "\n",
    "# MSSubClass is a categorical variable with numeric categories. Avoid treating it as\n",
    "# numeric/ordinal:\n",
    "df_comb.loc[:, 'MSSubClass'] = df_comb['MSSubClass'].astype('str')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  1 - manual feature engineering\n",
    "\n",
    "Transformations are registered as functions that take 1 argument, a DataFrame, and return a DataFrame. They're added to a list and then executed sequentially.\n",
    "By specifying them as functions, rather than executing them directly, we can test what their impact is on the CV score. We'll then only use the ones that actually improve the score.\n",
    "\n",
    "There isn't much of an ordering in here. I started following the order in Kaggle's `data_description.txt`, but soon realised that that would take too much time, so I started grouping some similar columns and treating them in the same way. Anyway - the order corresponds to the explorative analysis notebook. That notebook contains the rationale for these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_mssubclass(df):\n",
    "    col = 'MSSubClass'\n",
    "    df.loc[df[col].isin(['40', '160']), col] = '40_160'\n",
    "    df.loc[df[col].isin(['70', '20', '75']), col] = '70_20_75'\n",
    "    df.loc[df[col].isin(['190', '50', '90']), col] = '190_50_90'\n",
    "    df.loc[df[col].isin(['30', '45', '180']), col] = '30_45_180'\n",
    "    df.loc[df[col] == '150', col] = np.nan\n",
    "    return df\n",
    "transformations.append(trans_mssubclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_lotshape(df):\n",
    "    old_col = 'LotShape'\n",
    "    new_col = 'RegularLotShape'\n",
    "    df.loc[df[old_col] == 'Reg', new_col] = 1\n",
    "    df.loc[df[old_col] == 'IR1', new_col] = 0\n",
    "    df.loc[df[old_col] == 'IR2', new_col] = 0\n",
    "    df.loc[df[old_col] == 'IR3', new_col] = 0\n",
    "    df[new_col] = df[new_col].astype(int)\n",
    "    df = df.drop(old_col, axis=1)\n",
    "    return df\n",
    "transformations.append(trans_lotshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trans_landcontour(df):\n",
    "    df.loc[:, 'LandLvlOrBnk'] = 0\n",
    "    df.loc[df['LandContour'].isin(('Lvl','Bnk')), 'LandLvlOrBnk'] = 1\n",
    "    df = df.drop('LandContour', axis=1)\n",
    "    return df\n",
    "transformations.append(trans_landcontour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_lotconfig(df):\n",
    "    df.loc[df['LotConfig'].isin(('FR3','CulDSac')), 'LotConfig'] = 'FR3_or_CulDSac'\n",
    "    df.loc[df['LotConfig'].isin(('Inside','Corner')), 'LotConfig'] = 'Inside_or_Corner'\n",
    "    return df\n",
    "transformations.append(trans_lotconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_landslope(df):\n",
    "    old_col_name = 'LandSlope'\n",
    "    new_col_name = 'LandSlopeGtl'\n",
    "    df.loc[:, new_col_name] = 0\n",
    "    df.loc[df[old_col_name].isin(['Gtl']), new_col_name] = 1\n",
    "    df = df.drop(old_col_name, axis=1)\n",
    "    return df\n",
    "transformations.append(trans_landslope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_neighborhood(df):\n",
    "    old_col_name = 'Neighborhood'\n",
    "    new_col_cheap = 'CheapNeighborhood'\n",
    "    new_col_exp = 'ExpensiveNeighborhood'\n",
    "    df.loc[:, new_col_cheap] = 0\n",
    "    df.loc[:, new_col_exp] = 0\n",
    "    \n",
    "    nb_sp = df_comb.groupby('Neighborhood')[['SalePrice']].median()\n",
    "    df.loc[df[old_col_name].isin(\n",
    "        nb_sp[nb_sp['SalePrice'] > 200000]\n",
    "            .index.get_level_values(0).values), new_col_exp] = 1\n",
    "    \n",
    "    df.loc[df[old_col_name].isin(\n",
    "        nb_sp[nb_sp['SalePrice'] < 160000]\n",
    "            .index.get_level_values(0).values), new_col_cheap] = 1\n",
    "    \n",
    "    df = df.drop(old_col_name, axis=1)\n",
    "    return df\n",
    "transformations.append(trans_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_add_is_new(df):\n",
    "    col = 'IsNew'\n",
    "    df.loc[:, col] = 0\n",
    "    df.loc[(df['YearBuilt'] == df['YrSold']) | \n",
    "            (df['YearBuilt']-1 == df['YrSold']), col] = 1\n",
    "    return df\n",
    "transformations.append(trans_add_is_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_add_remodel(df):\n",
    "    col = 'RecentRemodel'\n",
    "    df.loc[:, col] = 0\n",
    "    df.loc[(df['YearRemodAdd'] >= df['YrSold']), col] = 1\n",
    "    return df\n",
    "transformations.append(trans_add_remodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_fix_year_remod_add(df):\n",
    "    df.loc[(df['YearRemodAdd'] == 1950) & \n",
    "            (df['YearBuilt'] < 1950), 'YearBuilt'] = df['YearBuilt']\n",
    "    return df\n",
    "transformations.append(trans_fix_year_remod_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_yrsold(df):\n",
    "    return df.drop('YrSold', axis=1)\n",
    "transformations.append(trans_del_yrsold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_mosold(df):\n",
    "    return df.drop('MoSold', axis=1)\n",
    "transformations.append(trans_del_mosold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_roofmatl(df):\n",
    "    return df.drop('RoofMatl', axis=1)\n",
    "transformations.append(trans_del_roofmatl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_roof_style(df):\n",
    "    col = 'RoofStyle'                                         \n",
    "    df.loc[df[col].isin(('Gambrel','Gable')), col] = 'GG'\n",
    "    df.loc[df[col].isin(('Mansard','Hip', 'Flat', 'Shed')), col] = 'MHFS'\n",
    "    return df\n",
    "transformations.append(trans_roof_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_condition(df):\n",
    "    col1 = 'Condition1'\n",
    "    col2 = 'Condition2'\n",
    "    \n",
    "    col_art = 'CloseToArtery'\n",
    "    df.loc[:, col_art] = 0\n",
    "    df.loc[(df[col1] == 'Artery') | \n",
    "            (df[col2] == 'Artery'), col_art] = 1\n",
    "    \n",
    "    col_feeder = 'CloseToFeeder'\n",
    "    df.loc[:, col_feeder] = 0\n",
    "    df.loc[(df[col1] == 'Feedr') | \n",
    "            (df[col2] == 'Feedr'), col_feeder] = 1\n",
    "    \n",
    "    df = df.drop([col1, col2], axis=1)\n",
    "    return df\n",
    "transformations.append(trans_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_exterior(df):\n",
    "    col1 = 'Exterior1st'\n",
    "    col2 = 'Exterior2nd'\n",
    "    col_cheap = 'ExteriorMaterialCheap'\n",
    "    col_medium = 'ExteriorMaterialMedium'\n",
    "    col_exp = 'ExteriorMaterialExpensive'\n",
    "    mat_cheap = ['AsbShng', 'WdShing', 'Wd Sdng', 'MetalSd']\n",
    "    mat_medium = ['Stucco', 'HdBoard', 'BrkFace', 'Plywood']\n",
    "    mat_exp = ['VinylSd', 'CemntBd', 'CmentBd', 'ImStucc']\n",
    "    \n",
    "    def create_combined_col(df, new_col_name, materials):\n",
    "        nonlocal col1, col2\n",
    "        df.loc[:, new_col_name] = 0\n",
    "        df.loc[(df[col1].isin(materials)) | (df[col2].isin(materials)), new_col_name] = 1\n",
    "        return df\n",
    "    \n",
    "    df = create_combined_col(df, col_cheap, mat_cheap)\n",
    "    df = create_combined_col(df, col_medium, mat_medium)\n",
    "    df = create_combined_col(df, col_exp, mat_exp)\n",
    "\n",
    "    df = df.drop([col1, col2], axis=1)\n",
    "    return df\n",
    "transformations.append(trans_exterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_salecondition(df):\n",
    "    return df.drop('SaleCondition', axis=1)\n",
    "transformations.append(trans_del_salecondition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_saletype(df):\n",
    "    return df.drop('SaleType', axis=1)\n",
    "transformations.append(trans_del_saletype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_housestyle(df):\n",
    "    col = 'HouseStyle'\n",
    "    df.loc[(df[col].isin(['2.5Fin', '2Story'])), col] = '2.5Fin_Or_2Story'\n",
    "    df.loc[(df[col].isin(['2.5Unf', '1.5Fin'])), col] = '2.5Unf_Or_1.5Fin'\n",
    "    return df\n",
    "transformations.append(trans_housestyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_foundation(df):\n",
    "    col = 'Foundation'\n",
    "    df.loc[(df[col] == 'Stone'), col] = np.nan\n",
    "    df.loc[(df[col] == 'Wood'), col] = np.nan\n",
    "    return df\n",
    "transformations.append(trans_foundation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_heating(df):\n",
    "    col = 'Heating'\n",
    "    df.loc[(df[col].isin(['Floor', 'OthW'])), col] = np.nan\n",
    "    return df\n",
    "transformations.append(trans_heating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_log(df):\n",
    "    cols = ['1stFlrSF', 'LotFrontage', 'GrLivArea', 'LotArea', 'LotFrontage']\n",
    "    for col in cols:\n",
    "        df = log_transform_helper(df, col)\n",
    "    return df\n",
    "transformations.append(trans_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_sqrt_gararea(df):\n",
    "    return sqrt_transform_helper(df, 'GarageArea')\n",
    "transformations.append(trans_sqrt_gararea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_log_openporch(df):\n",
    "    return log_transform_helper(df, 'OpenPorchSF')\n",
    "transformations.append(trans_log_openporch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_sqrt(df):\n",
    "    cols = ['MasVnrArea', 'TotalBsmtSF', 'WoodDeckSF']\n",
    "    for col in cols:\n",
    "        df = sqrt_transform_helper(df, col)\n",
    "    return df\n",
    "transformations.append(trans_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_numeric(df):\n",
    "    cols = ['3SsnPorch', 'BsmtFinSF2', 'BsmtFinType2', 'EnclosedPorch', 'LowQualFinSF', \n",
    "            'MiscVal', 'ScreenPorch']\n",
    "    return df.drop(cols, axis=1)\n",
    "transformations.append(trans_del_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_outliers(df):\n",
    "    def del_outl(condition, field):\n",
    "        nonlocal df\n",
    "        df.loc[condition, field] = None\n",
    "    \n",
    "    del_outl(df['GarageYrBlt'] > 2100, 'GarageYrBlt')\n",
    "    del_outl((df['GrLivArea'] > 4000) & (df[COL_Y] < np.log(200000)), 'GrLivArea')\n",
    "    del_outl(df['TotalBsmtSF'] > 6000, 'TotalBsmtSF')\n",
    "    del_outl(df['LotFrontage'] > 300, 'LotFrontage')\n",
    "    del_outl((df['OpenPorchSF'] > 300) & (df[COL_Y] < np.log(100000)), 'OpenPorchSF')\n",
    "    return df\n",
    "\n",
    "# This should obviously be done BEFORE log/sqrt transformations are applied! \n",
    "# So insert(0,..) rather than append.\n",
    "transformations.insert(0, trans_del_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_outliers_2(df):\n",
    "    def del_outl(condition, field):\n",
    "        nonlocal df\n",
    "        df.loc[condition, field] = None \n",
    "\n",
    "    del_outl(df['BsmtFinSF1'] > 4000, 'BsmtFinSF1')\n",
    "    del_outl((df['1stFlrSF'] > 2700) & (df[COL_Y].isnull() == False), '1stFlrSF')\n",
    "    del_outl((df['2ndFlrSF'] > 1750) & (df[COL_Y] < np.log(300000)), '2ndFlrSF')\n",
    "    del_outl((df['TotalBsmtSF'] > 3000) & (df[COL_Y] < np.log(200000)), 'TotalBsmtSF')\n",
    "    del_outl((df['GarageArea'] > 1200) & (df[COL_Y] < 12.5), 'GarageArea')\n",
    "    del_outl(df['LotArea'] > 100000, 'LotArea')\n",
    "    del_outl((df['LotFrontage'] > 140) & (df['LotFrontage'] < 160) & (df[COL_Y] < 11), 'LotFrontage')\n",
    "    del_outl(df['MasVnrArea'] > 1500, 'MasVnrArea')\n",
    "    del_outl((df['OpenPorchSF'] > 500) & (df[COL_Y] < np.log(50000)), 'OpenPorchSF')\n",
    "    return df\n",
    "transformations.insert(0, trans_del_outliers_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_fireplace(df):\n",
    "    col = 'Fireplaces'\n",
    "    new_col1 = 'HasAFireplace'\n",
    "    new_col2plus = 'HasMoreThan1Fireplace'\n",
    "    df.loc[:, new_col1] = 0\n",
    "    df.loc[:, new_col2plus] = 0\n",
    "    df.loc[df[col] >= 1, new_col1] = 1\n",
    "    df.loc[df[col] >= 2, new_col2plus] = 1\n",
    "    df = df.drop(col, axis=1)\n",
    "    return df\n",
    "transformations.append(trans_fireplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_quality_to_ordinal(df):\n",
    "    def convert_ordinal_cat_to_int(df, col):\n",
    "        df.loc[df[col].isnull(), col] = '__missing'\n",
    "        grouped_ordered = df[[col, COL_Y]].groupby(col).median().sort_values(by=COL_Y)\n",
    "        q_map = {}\n",
    "        for i, key in enumerate(grouped_ordered.index):\n",
    "            q_map[key] = i\n",
    "        df[col] = df[col].map(q_map)\n",
    "        return df\n",
    "    \n",
    "    ordinal_quality_cols = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', \n",
    "                            'BsmtCond', \n",
    "                            'ExterCond',  'ExterQual', 'FireplaceQu', 'Fence',\n",
    "                            'GarageCond', 'GarageFinish', 'GarageQual', 'PavedDrive',\n",
    "                            'HeatingQC', 'KitchenQual',  'Functional'] \n",
    "    for col in ordinal_quality_cols:\n",
    "        df = convert_ordinal_cat_to_int(df, col)\n",
    "        \n",
    "    return df\n",
    "transformations.append(trans_quality_to_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def trans_del_outliers_3sig(df):\n",
    "#     num_stds = 3\n",
    "#     num_cols = [c for c in df.columns if df[c].dtype != 'object' and c != COL_Y]\n",
    "#     for col in num_cols:\n",
    "#         std = np.std(df[col])\n",
    "#         mean = np.mean(df[col])\n",
    "#         df.loc[np.abs(df[col] - mean) > num_stds * std, col] = np.nan\n",
    "#     return df\n",
    "# COMMENTED; this seems good in isolation but reduced score on public leaderbord from .116 to .128\n",
    "# transformations.append(trans_del_outliers_3sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether transformations actually improve score\n",
    "I don't want to just use intuition for these transformations - they should make sense and actually improve the score. Since we have such a small dataset, we can easily repeat a full grid search CV in a short amount of time.\n",
    "Below, every transformation is applied independently and we compare the performance against the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_del_outliers_2           base: 0.134 (± 0.036) | trans: 0.121 (± 0.019) | Effect: -10.00%\n",
      "trans_del_outliers             base: 0.134 (± 0.036) | trans: 0.115 (± 0.016) | Effect: -14.49%\n",
      "trans_mssubclass               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.30%\n",
      "trans_lotshape                 base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.17%\n",
      "trans_landcontour              base: 0.134 (± 0.036) | trans: 0.135 (± 0.037) | Effect:   0.23%\n",
      "trans_lotconfig                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.12%\n",
      "trans_landslope                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.01%\n",
      "trans_neighborhood             base: 0.134 (± 0.036) | trans: 0.139 (± 0.039) | Effect:   3.40%\n",
      "trans_add_is_new               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.03%\n",
      "trans_add_remodel              base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.08%\n",
      "trans_fix_year_remod_add       base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
      "trans_del_yrsold               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.08%\n",
      "trans_del_mosold               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.12%\n",
      "trans_del_roofmatl             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.11%\n",
      "trans_roof_style               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.08%\n",
      "trans_condition                base: 0.134 (± 0.036) | trans: 0.134 (± 0.034) | Effect:   0.09%\n",
      "trans_exterior                 base: 0.134 (± 0.036) | trans: 0.134 (± 0.035) | Effect:  -0.25%\n",
      "trans_del_salecondition        base: 0.134 (± 0.036) | trans: 0.135 (± 0.035) | Effect:   0.42%\n",
      "trans_del_saletype             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.12%\n",
      "trans_housestyle               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.03%\n",
      "trans_foundation               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
      "trans_heating                  base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
      "trans_log                      base: 0.134 (± 0.036) | trans: 0.126 (± 0.028) | Effect:  -5.95%\n",
      "trans_sqrt_gararea             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.13%\n",
      "trans_log_openporch            base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.34%\n",
      "trans_sqrt                     base: 0.134 (± 0.036) | trans: 0.131 (± 0.033) | Effect:  -2.64%\n",
      "trans_del_numeric              base: 0.134 (± 0.036) | trans: 0.136 (± 0.036) | Effect:   1.14%\n",
      "trans_fireplace                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.11%\n",
      "trans_quality_to_ordinal       base: 0.134 (± 0.036) | trans: 0.135 (± 0.037) | Effect:   0.14%\n"
     ]
    }
   ],
   "source": [
    "def ridge_cv_test_score(df_in, trans, alpha_range):\n",
    "    \"\"\"Do a 10-fold CV and return the mean score. Internally uses RidgeCV with its\n",
    "    internal LOOCV loop to find a good value for alpha.\n",
    "    Splits data into a training and a test set first. Score on test set will be returned.\n",
    "    \n",
    "    :param df_in: full dataframe\n",
    "    :param trans: list of transformations (could be empty)\n",
    "    :param alpha range: range of alpha values for Ridge regression model\n",
    "    :return 2-tuple: mean score, std of k-fold CV\n",
    "    \"\"\"\n",
    "    df_train, y_train, _ = prep_data(df_in, COL_Y, trans)\n",
    "    return calc_kfold_score(RidgeCV(alphas=alpha_range), \n",
    "                                    df_train, y_train, n_splits=10, shuffle=False)\n",
    "\n",
    "def transformation_effectiveness_new2(df_in, alpha_range, trans_list):\n",
    "    df_in = df_in[df_in[COL_Y].isnull() == False]\n",
    "\n",
    "    effective_transformations = []\n",
    "    \n",
    "    for trans in trans_list:        \n",
    "        # Shuffle DF. We're doing this here rather than in \n",
    "        # KFold to ensure we get the same folds in baseline & w/ trans applied.\n",
    "        df_in = df_in.sample(frac=1)  \n",
    "        baseline_score, baseline_std = ridge_cv_test_score(df_in, [], alpha_range)\n",
    "        trans_score, trans_std = ridge_cv_test_score(df_in, [trans], alpha_range)\n",
    "        percentage_diff = (trans_score - baseline_score) / baseline_score * 100\n",
    "        \n",
    "        if percentage_diff < 0:\n",
    "            effective_transformations.append(trans)\n",
    "\n",
    "        print(\"{:30s} base: {:.3f} (± {:.3f}) | trans: {:.3f} (± {:.3f}) \"\n",
    "              \"| Effect: {:6.2f}%\"\n",
    "              .format(trans.__name__, baseline_score, baseline_std, trans_score, trans_std, percentage_diff))\n",
    "    return effective_transformations\n",
    "\n",
    "alpha_range = np.concatenate((np.arange(1, 10, .5), \n",
    "                              np.arange(10, 20, 1), \n",
    "                              np.arange(20, 60, 2.5)))\n",
    "\n",
    "effective_transformations = transformation_effectiveness_new2(\n",
    "    df_comb, alpha_range, transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the results for future reference (it takes some time to execute and the cell contents disappear when experimenting):\n",
    "\n",
    "    trans_del_outliers_2           base: 0.134 (± 0.036) | trans: 0.121 (± 0.019) | Effect: -10.00%\n",
    "    trans_del_outliers             base: 0.134 (± 0.036) | trans: 0.115 (± 0.016) | Effect: -14.49%\n",
    "    trans_mssubclass               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.30%\n",
    "    trans_lotshape                 base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.17%\n",
    "    trans_landcontour              base: 0.134 (± 0.036) | trans: 0.135 (± 0.037) | Effect:   0.23%\n",
    "    trans_lotconfig                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.12%\n",
    "    trans_landslope                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.01%\n",
    "    trans_neighborhood             base: 0.134 (± 0.036) | trans: 0.139 (± 0.039) | Effect:   3.40%\n",
    "    trans_add_is_new               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.03%\n",
    "    trans_add_remodel              base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.08%\n",
    "    trans_fix_year_remod_add       base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
    "    trans_del_yrsold               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.08%\n",
    "    trans_del_mosold               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.12%\n",
    "    trans_del_roofmatl             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.11%\n",
    "    trans_roof_style               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.08%\n",
    "    trans_condition                base: 0.134 (± 0.036) | trans: 0.134 (± 0.034) | Effect:   0.09%\n",
    "    trans_exterior                 base: 0.134 (± 0.036) | trans: 0.134 (± 0.035) | Effect:  -0.25%\n",
    "    trans_del_salecondition        base: 0.134 (± 0.036) | trans: 0.135 (± 0.035) | Effect:   0.42%\n",
    "    trans_del_saletype             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.12%\n",
    "    trans_housestyle               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.03%\n",
    "    trans_foundation               base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
    "    trans_heating                  base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:   0.00%\n",
    "    trans_log                      base: 0.134 (± 0.036) | trans: 0.126 (± 0.028) | Effect:  -5.95%\n",
    "    trans_sqrt_gararea             base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.13%\n",
    "    trans_log_openporch            base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.34%\n",
    "    trans_sqrt                     base: 0.134 (± 0.036) | trans: 0.131 (± 0.033) | Effect:  -2.64%\n",
    "    trans_del_numeric              base: 0.134 (± 0.036) | trans: 0.136 (± 0.036) | Effect:   1.14%\n",
    "    trans_fireplace                base: 0.134 (± 0.036) | trans: 0.134 (± 0.036) | Effect:  -0.11%\n",
    "    trans_quality_to_ordinal       base: 0.134 (± 0.036) | trans: 0.135 (± 0.037) | Effect:   0.14%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative percentual difference compared to the baseline performance is a good thing. If it's positive, it means that the transformation didn't really pan out as expected and actually decreased performance.\n",
    "\n",
    "Important lesson learned earlier on: there's way too much variance in the results with Boosted Trees. It can't be used to base decisions on. Ridge regression, on the other hand, is *very* stable. As long as - and this is very important - we do a grid search to find right value for alpha, because this differs a lot depending on how many variables are remaining after applying the transformation.\n",
    "\n",
    "Downside of this approach that we're only basing decisions to include or exclude transformations on just one model (a linear model in this case). The result is that we might make choices to optimize linear models at the expense of Boosted Tree performance. Another blind spot is combinations of transformations. I think this an acceptable risk, and empirically I've found that improvements measured here consistently lead to improvements on the leaderboard with the model ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  2 - apply automatic imputation and conversions\n",
    "\n",
    "`prep_data` is a neat function that takes a DF, makes a local copy, and does the following:\n",
    "\n",
    "1. apply manual transformations\n",
    "2. apply KNN imputer to fill missing data\n",
    "3. apply automatic transformations (i.e. standardization, label encoder, one hot encoding)\n",
    "4. split df into df_train, y_train (a Series), df_test\n",
    "    \n",
    "It then returns the transformed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** Applying manual transformations\n",
      " -> Manual transformation trans_del_outliers_2\n",
      " -> Manual transformation trans_del_outliers\n",
      " -> Manual transformation trans_mssubclass\n",
      " -> Manual transformation trans_lotshape\n",
      " -> Manual transformation trans_landslope\n",
      " -> Manual transformation trans_add_is_new\n",
      " -> Manual transformation trans_del_mosold\n",
      " -> Manual transformation trans_roof_style\n",
      " -> Manual transformation trans_exterior\n",
      " -> Manual transformation trans_housestyle\n",
      " -> Manual transformation trans_log\n",
      " -> Manual transformation trans_sqrt_gararea\n",
      " -> Manual transformation trans_log_openporch\n",
      " -> Manual transformation trans_sqrt\n",
      " -> Manual transformation trans_fireplace\n",
      "\n",
      " ** Starting knn_impute\n",
      "\n",
      " ** Starting auto-transform\n",
      " -> 75 columns in df before transformations\n",
      " -> Result of automatic column splitting: \n",
      " ---> Numeric/Ordinal: [No further transformation] ['BedroomAbvGr', 'BsmtFullBath', 'BsmtHalfBath', 'ExteriorMaterialCheap', 'ExteriorMaterialExpensive', 'ExteriorMaterialMedium', 'FullBath', 'GarageCars', 'HalfBath', 'HasAFireplace', 'HasMoreThan1Fireplace', 'IsNew', 'KitchenAbvGr', 'LandSlopeGtl', 'OverallCond', 'OverallQual', 'RegularLotShape', 'TotRmsAbvGrd', 'YrSold']\n",
      " ---> Numerical: [Standardized: mean removal and unit std] ['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'EnclosedPorch', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MasVnrArea', 'MiscVal', 'OpenPorchSF', 'ScreenPorch', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd']\n",
      " ---> Categorical with <= 2 vars [LabelEnc] ['CentralAir', 'RoofStyle', 'Street']\n",
      " ---> Categorical with > 2 vars [OneHot] ['BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Condition1', 'Condition2', 'ExterCond', 'ExterQual', 'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', 'LotConfig', 'MSSubClass', 'MSZoning', 'MasVnrType', 'Neighborhood', 'PavedDrive', 'RoofMatl', 'SaleCondition', 'SaleType']\n",
      " -> 251 columns in df after transformations\n",
      "\n",
      " ** Training df has 251 columns and 1460 rows, test df has 251 columns and 1459 rows\n"
     ]
    }
   ],
   "source": [
    "df_train, y_train, df_test = prep_data(df_comb, COL_Y, effective_transformations, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a bunch of models with default parameters\n",
    "\n",
    "*Except for GBR: I added params I found during grid search to get quick feedback on changes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:19:33 GradientBoostingRegressor train:  0.074, 10-fold cv:  0.114 (+- 0.016)\n",
      "2017-08-16 15:19:33 Ridge                     train:  0.095, 10-fold cv:  0.116 (+- 0.012)\n",
      "2017-08-16 15:19:33 Lasso                     train:  0.399, 10-fold cv:  0.399 (+- 0.028)\n",
      "2017-08-16 15:19:33 ElasticNet                train:  0.399, 10-fold cv:  0.398 (+- 0.031)\n",
      "2017-08-16 15:19:33 RandomForestRegressor     train:  0.074, 10-fold cv:  0.144 (+- 0.019)\n",
      "2017-08-16 15:19:33 SVR                       train:  0.099, 10-fold cv:  0.118 (+- 0.013)\n"
     ]
    }
   ],
   "source": [
    "models = [GradientBoostingRegressor(**{'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, \n",
    "                                       'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 600, \n",
    "                                       'subsample': 0.7}), \n",
    "          Ridge(),\n",
    "          Lasso(),\n",
    "          ElasticNet(),\n",
    "          RandomForestRegressor(), \n",
    "          SVR(kernel='rbf'),\n",
    "         ]\n",
    "\n",
    "dt_now = datetime.now().replace(microsecond=0)\n",
    "n_folds = 10\n",
    "for model in models:\n",
    "    model.fit(df_train, y_train)\n",
    "    kf_mean, kf_std = calc_kfold_score(model, df_train, y_train, n_splits=n_folds)\n",
    "    print(\"{} {:25s} train: {:6.3f}, {}-fold cv: {:6.3f} (+- {:0.3f})\"\n",
    "          .format(dt_now, model.__class__.__name__, \n",
    "                  rmsle(y_train, model.predict(df_train)), n_folds,\n",
    "                  kf_mean, kf_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how Ridge, Lasso and ElasticNet perform very badly without hyperparameter tuning. I'm doing that in the following cells.\n",
    "\n",
    "Also tried:\n",
    "- SVR with poly or linear kernel... rbf performed better\n",
    "- GaussianProcessRegressor: overfits very badly with default settings. Might not be suitable for such a high dimensionality. Could research this further at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters\n",
    "Note: GridSearchCV by default refits the estimator using the best found parameters. We use this to do the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:20:00 best score: 0.1131, best params: {'alpha': 8.0}\n"
     ]
    }
   ],
   "source": [
    "alpha_range = np.arange(1, 50, .25)\n",
    "best_ridge, best_ridge_params, _ = gridcv(df_train, y_train, Ridge(), {\n",
    "        \"alpha\": alpha_range\n",
    "    }, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:20:00 best score: 0.1152, best params: {'alpha': 0.0003}\n"
     ]
    }
   ],
   "source": [
    "best_lasso, best_lasso_params, _ = gridcv(df_train, y_train, Lasso(), {\n",
    "    'alpha': [.0003, .0006, .001, .006, .01, .025, .05, .1, .25, .5, 1., 1.1]\n",
    "}, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:21:00 best score: 0.1136, best params: {'alpha': 0.0006, 'l1_ratio': 0.4, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "best_elastic, best_elastic_params, _ = gridcv(df_train, y_train, ElasticNet(), {\n",
    "    'alpha': [.0003, .0006, .001, .006, .01, .025, .05, .1, .25, .5, 1., 1.1],\n",
    "    'max_iter': [10000],\n",
    "    'l1_ratio': [0.01, .2, .25, .3, .35, .4, .5, .6, .7, .75, .8, .85, .9, 1]\n",
    "}, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:26:00 best score: 0.1130, best params: {'C': 1.9000000000000004, 'epsilon': 0.03, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "best_svr, best_svr_params, _ = gridcv(df_train, y_train, SVR(), {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': np.arange(0.25, 2, .15),\n",
    "        'epsilon': [.001, .03, .01, .1]\n",
    "    }, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 15:36:00 best score: 0.1131, best params: {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 600, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "best_gb, best_gb_params, _ = gridcv(df_train, y_train, GradientBoostingRegressor(), {\n",
    "     #'loss': ['ls', 'lad', 'huber', 'quantile'],   \n",
    "     'loss': ['huber'],  # It always seems to pick 'huber'\n",
    "     'n_estimators': [600, 700, 800], \n",
    "#     'max_depth': [2, 3],\n",
    "     'max_depth': [2],\n",
    "#     'learning_rate': [.01, .1, .2],\n",
    "     'learning_rate': [.1],\n",
    "     'min_samples_split': [3, 4, 5, 6],\n",
    "     'min_samples_leaf': [1, 2],\n",
    "     'subsample': [.6, .7, .8]\n",
    "}, n_jobs=8, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# best_xgb, best_xgb_params, _ = gridcv(df_train, y_train, xgb.XGBRegressor(), {\n",
    "#     'max_depth': [2, 3], \n",
    "#     'learning_rate': [.1,], \n",
    "#     'n_estimators': [500, 600, 700],\n",
    "#     'gamma': [0, .01, .1],\n",
    "#     'min_child_weight': [1, 2],\n",
    "#     'subsample': [.7, .8, .9],\n",
    "#     'colsample_bytree': [.7, .8, .9, 1],\n",
    "#     'colsample_bylevel': [.8, .9, 1],\n",
    "#     'reg_alpha': [0, .1],\n",
    "#     'reg_lambda': [1, 1.1, 1.2, 1.5, 2]\n",
    "# }, n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I seem to get a better CV score with sklearn's gradient boost than with XGBoost. I let the code in the cell above run for like 3 hours, very big grid search, but no dice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission\n",
    "Some sort of ensemble gives the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create_submission(best_elastic, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = create_submission_from_ensemble(\n",
    "    [best_ridge, best_gb, best_svr, best_elastic], df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze gradient boosting feature importances\n",
    "I used this to fuel investigation in the explorative data analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.059638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.047640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.041180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>0.041088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>0.036228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.033969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.033412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>0.033277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>0.032212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.032007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>RoofMatl_Membran</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Heating_Floor</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Condition1_RRNn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Condition1_RRNe</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Condition1_RRAn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>HouseStyle_SFoyer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>BsmtExposure_NoBsmt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>BsmtFinType1_Unf</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Foundation_Stone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>BsmtFinType2_Unf</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cols       imp\n",
       "15             GrLivArea  0.059638\n",
       "25           OverallQual  0.047640\n",
       "0               1stFlrSF  0.041180\n",
       "18               LotArea  0.041088\n",
       "19           LotFrontage  0.036228\n",
       "32             YearBuilt  0.033969\n",
       "30           TotalBsmtSF  0.033412\n",
       "8              BsmtUnfSF  0.033277\n",
       "12            GarageArea  0.032212\n",
       "4             BsmtFinSF1  0.032007\n",
       "188     RoofMatl_Membran  0.000000\n",
       "120        Heating_Floor  0.000000\n",
       "185      Condition1_RRNn  0.000000\n",
       "184      Condition1_RRNe  0.000000\n",
       "183      Condition1_RRAn  0.000000\n",
       "70     HouseStyle_SFoyer  0.000000\n",
       "76   BsmtExposure_NoBsmt  0.000000\n",
       "176     BsmtFinType1_Unf  0.000000\n",
       "81      Foundation_Stone  0.000000\n",
       "250     BsmtFinType2_Unf  0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({\"cols\": df_train.columns, \"imp\": best_gb.feature_importances_}) \\\n",
    "        .sort_values(by='imp', ascending=False)\n",
    "pd.concat((imp.head(10), imp.tail(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4401d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(imp['imp'].values, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
