{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning for for Kaggle House Price prediction\n",
    "==================\n",
    "The basic approach is as follows:\n",
    "\n",
    "\n",
    "### Data preparation:\n",
    "1) Define manual transformations that I decided on during explorative data analysis (see `Explorative_Data_Analysis.ipynb`)\n",
    "\n",
    "2) Apply automatic transformations: one-hot-encoding for categorical columns with > 2 categories, labelencoding for categorical columns with 2 categories, standardizing numeric values (that aren't ordinal in nature).\n",
    "\n",
    "3) Apply K-Nearest-Neighbour imputation for missing values. For each missing value, look at the nearest neighbour (i.e. most similar house), and use the value from the first neighbour that has it filled in.\n",
    "\n",
    "### Manual transformation filtering:\n",
    "4) Transformation Effectiveness: try each manual transformation to determine effectiveness on CV score with a linear model. For each transformation, apply steps 2 and 3 and determine performance compared to baseline. Keep only manual transormations that improve CV score.\n",
    "\n",
    "### Ensembling\n",
    "5) Do a cross-validatated Grid Search for a linear model (Ridge regression), Support Vector Regressor and Gradient Boosting Regressor. Calculate ensembled scores (unweighted mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "\n",
    "from preprocess import prep_data\n",
    "from utils import rmsle, rmsle_sk, create_submission, create_submission_from_ensemble, \\\n",
    "                  sqrt_transform_helper, log_transform_helper, ihs_transform_helper\n",
    "from crossval import calc_kfold_score, gridcv\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COL_Y = 'SalePrice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 2919 n_cols:  80\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv', index_col='Id')\n",
    "df_test = pd.read_csv('data/test.csv', index_col='Id')\n",
    "df_comb = pd.concat((df_train, df_test))\n",
    "\n",
    "print(\"n:\", len(df_comb), \"n_cols: \", len(df_comb.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some mandatory conversions\n",
    "\n",
    "These conversion must be performed. Reasons include data that's read incorrectly, has too many missing values for our imputation algorithm to handle, or other code relies on it having been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other code assumes log transform on the output variable so it's kind of non-optional:\n",
    "df_comb[COL_Y] = np.log(df_comb[COL_Y].values)\n",
    "\n",
    "# Too many missing values:\n",
    "df_comb = df_comb.drop('Alley', axis=1)  \n",
    "\n",
    "# MSSubClass is a categorical variable with numeric categories. Prevent treating them as\n",
    "# numeric/ordinal:\n",
    "df_comb.loc[:, 'MSSubClass'] = df_comb['MSSubClass'].astype('str')  \n",
    "\n",
    "# There's very few houses with a pool, only about 13. Too few to impute. I don't think \n",
    "# the area of the pool or the quality makes a meaningful difference with numbers this \n",
    "# small. Let's make it a boolean and ignore quality.\n",
    "df_comb['hasPool'] = df_comb['PoolArea'].map(lambda v: 1 if v > 0 else 0)\n",
    "df_comb = df_comb.drop(['PoolQC', 'PoolArea'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  1 - manual feature engineering\n",
    "\n",
    "Transformations are registered as functions that take 1 argument, a DataFrame, and return a DataFrame. They're added to a list and then executed sequentially.\n",
    "By specifying them as functions, rather than executing them directly, we can test what their impact is on the CV score. We'll then only use the ones that actually improve the score.\n",
    "\n",
    "There isn't much of an ordering in here. I started following the order in Kaggle's `data_description.txt`, but soon realised that that would take too much time, so I started grouping some similar columns and treating them in the same way. Anyway - the order corresponds to the explorative analysis notebook. That notebook contains the rationale for these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_mssubclass(df_):\n",
    "    col = 'MSSubClass'\n",
    "    df_.loc[df_[col].isin(['40', '160']), col] = '40_160'\n",
    "    df_.loc[df_[col].isin(['70', '20', '75']), col] = '70_20_75'\n",
    "    df_.loc[df_[col].isin(['190', '50', '90']), col] = '190_50_90'\n",
    "    df_.loc[df_[col].isin(['30', '45', '180']), col] = '30_45_180'\n",
    "    df_.loc[df_[col] == '150', col] = np.nan\n",
    "    return df_\n",
    "transformations.append(trans_mssubclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_lotshape(df_):\n",
    "    old_col = 'LotShape'\n",
    "    new_col = 'RegularLotShape'\n",
    "    df_.loc[df_[old_col] == 'Reg', new_col] = 1\n",
    "    df_.loc[df_[old_col] == 'IR1', new_col] = 0\n",
    "    df_.loc[df_[old_col] == 'IR2', new_col] = 0\n",
    "    df_.loc[df_[old_col] == 'IR3', new_col] = 0\n",
    "    df_[new_col] = df_[new_col].astype(int)\n",
    "    df_ = df_.drop(old_col, axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_lotshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trans_landcontour(df_):\n",
    "    df_.loc[:, 'LandLvlOrBnk'] = 0\n",
    "    df_.loc[df_['LandContour'].isin(('Lvl','Bnk')), 'LandLvlOrBnk'] = 1\n",
    "    df_ = df_.drop('LandContour', axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_landcontour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_utilities(df_):\n",
    "    return df_.drop('Utilities', axis=1)\n",
    "transformations.append(trans_del_utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_lotconfig(df_):\n",
    "    df_.loc[df_['LotConfig'].isin(('FR3','CulDSac')), 'LotConfig'] = 'FR3_or_CulDSac'\n",
    "    df_.loc[df_['LotConfig'].isin(('Inside','Corner')), 'LotConfig'] = 'Inside_or_Corner'\n",
    "    return df_\n",
    "transformations.append(trans_lotconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_landslope(df_):\n",
    "    old_col_name = 'LandSlope'\n",
    "    new_col_name = 'LandSlopeGtl'\n",
    "    df_.loc[:, new_col_name] = 0\n",
    "    df_.loc[df_[old_col_name].isin(['Gtl']), new_col_name] = 1\n",
    "    df_ = df_.drop(old_col_name, axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_landslope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_neighborhood(df_):\n",
    "    old_col_name = 'Neighborhood'\n",
    "    new_col_name = 'NeighborhoodIndex'\n",
    "    df_.loc[:, new_col_name] = 1\n",
    "    \n",
    "    nb_sp = df_comb.groupby('Neighborhood')[['SalePrice']].median()\n",
    "    df_.loc[df_[old_col_name].isin(\n",
    "        nb_sp[nb_sp['SalePrice'] > 200000]\n",
    "            .index.get_level_values(0).values), new_col_name] = 2\n",
    "    \n",
    "    df_.loc[df_[old_col_name].isin(\n",
    "        nb_sp[nb_sp['SalePrice'] < 160000]\n",
    "            .index.get_level_values(0).values), new_col_name] = 0\n",
    "    \n",
    "    df_ = df_.drop(old_col_name, axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_add_is_new(df_):\n",
    "    col = 'IsNew'\n",
    "    df_.loc[:, col] = 0\n",
    "    df_.loc[(df_['YearBuilt'] == df_['YrSold']) | \n",
    "            (df_['YearBuilt']-1 == df_['YrSold']), col] = 1\n",
    "    return df_\n",
    "transformations.append(trans_add_is_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_add_remodel(df_):\n",
    "    col = 'RecentRemodel'\n",
    "    df_.loc[:, col] = 0\n",
    "    df_.loc[(df_['YearRemodAdd'] >= df_['YrSold']), col] = 1\n",
    "    return df_\n",
    "transformations.append(trans_add_remodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_fix_year_remod_add(df_):\n",
    "    df_.loc[(df_['YearRemodAdd'] == 1950) & \n",
    "            (df_['YearBuilt'] < 1950), 'YearBuilt'] = df_['YearBuilt']\n",
    "    return df_\n",
    "transformations.append(trans_fix_year_remod_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_yrsold(df_):\n",
    "    return df_.drop('YrSold', axis=1)\n",
    "transformations.append(trans_del_yrsold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_mosold(df_):\n",
    "    return df_.drop('MoSold', axis=1)\n",
    "transformations.append(trans_del_mosold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_roofmatl(df_):\n",
    "    return df_.drop('RoofMatl', axis=1)\n",
    "transformations.append(trans_del_roofmatl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_roof_style(df_):\n",
    "    col = 'RoofStyle'                                         \n",
    "    df_.loc[df_[col].isin(('Gambrel','Gable')), col] = 'GG'\n",
    "    df_.loc[df_[col].isin(('Mansard','Hip', 'Flat', 'Shed')), col] = 'MHFS'\n",
    "    return df_\n",
    "transformations.append(trans_roof_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_miscfeature(df_):\n",
    "    return df_.drop('MiscFeature', axis=1)\n",
    "transformations.append(trans_del_miscfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_condition(df_):\n",
    "    col1 = 'Condition1'\n",
    "    col2 = 'Condition2'\n",
    "    \n",
    "    col_art = 'CloseToArtery'\n",
    "    df_.loc[:, col_art] = 0\n",
    "    df_.loc[(df_[col1] == 'Artery') | \n",
    "            (df_[col2] == 'Artery'), col_art] = 1\n",
    "    \n",
    "    col_feeder = 'CloseToFeeder'\n",
    "    df_.loc[:, col_feeder] = 0\n",
    "    df_.loc[(df_[col1] == 'Feedr') | \n",
    "            (df_[col2] == 'Feedr'), col_feeder] = 1\n",
    "    \n",
    "    df_ = df_.drop([col1, col2], axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_exterior(df_):\n",
    "    col1 = 'Exterior1st'\n",
    "    col2 = 'Exterior2nd'\n",
    "    col_cheap = 'ExteriorMaterialCheap'\n",
    "    col_medium = 'ExteriorMaterialMedium'\n",
    "    col_exp = 'ExteriorMaterialExpensive'\n",
    "    mat_cheap = ['AsbShng', 'WdShing', 'Wd Sdng', 'MetalSd']\n",
    "    mat_medium = ['Stucco', 'HdBoard', 'BrkFace', 'Plywood']\n",
    "    mat_exp = ['VinylSd', 'CemntBd', 'CmentBd', 'ImStucc']\n",
    "    \n",
    "    def create_combined_col(df_, new_col_name, materials):\n",
    "        nonlocal col1, col2\n",
    "        df_.loc[:, new_col_name] = 0\n",
    "        df_.loc[(df_[col1].isin(materials)) | (df_[col2].isin(materials)), new_col_name] = 1\n",
    "        return df_\n",
    "    \n",
    "    df_ = create_combined_col(df_, col_cheap, mat_cheap)\n",
    "    df_ = create_combined_col(df_, col_medium, mat_medium)\n",
    "    df_ = create_combined_col(df_, col_exp, mat_exp)\n",
    "    \n",
    "    df_ = df_.drop([col1, col2], axis=1)\n",
    "    return df_\n",
    "transformations.append(trans_exterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_salecondition(df_):\n",
    "    return df_.drop('SaleCondition', axis=1)\n",
    "transformations.append(trans_del_salecondition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_saletype(df_):\n",
    "    return df_.drop('SaleType', axis=1)\n",
    "transformations.append(trans_del_saletype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_housestyle(df_):\n",
    "    col = 'HouseStyle'\n",
    "    df_.loc[(df_[col].isin(['2.5Fin', '2Story'])), col] = '2.5Fin_Or_2Story'\n",
    "    df_.loc[(df_[col].isin(['2.5Unf', '1.5Fin'])), col] = '2.5Unf_Or_1.5Fin'\n",
    "    return df_\n",
    "transformations.append(trans_housestyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_masvnrtype(df_):\n",
    "    col = 'MasVnrType'\n",
    "    df_.loc[(df_[col].isin(['BrkCmn','None'])), col] = 'BrkCmnOrNone'\n",
    "    df_.loc[(df_[col].isnull() & df_['MasVnrArea'].isnull()), col] = 'BrkCmnOrNone'\n",
    "    return df_\n",
    "transformations.append(trans_masvnrtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_elec(df_):\n",
    "    return df_.drop('Electrical', axis=1)\n",
    "transformations.append(trans_del_elec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_foundation(df_):\n",
    "    col = 'Foundation'\n",
    "    df_.loc[(df_[col] == 'Stone'), col] = np.nan\n",
    "    df_.loc[(df_[col] == 'Wood'), col] = np.nan\n",
    "    return df_\n",
    "transformations.append(trans_foundation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_heating(df_):\n",
    "    col = 'Heating'\n",
    "    df_.loc[(df_[col].isin(['Floor', 'OthW'])), col] = np.nan\n",
    "    return df_\n",
    "transformations.append(trans_heating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_log(df_):\n",
    "    cols = ['1stFlrSF', 'LotFrontage', 'GrLivArea', 'LotArea', 'LotFrontage']\n",
    "    for col in cols:\n",
    "        df_ = log_transform_helper(df_, col)\n",
    "    return df_\n",
    "transformations.append(trans_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_sqrt_gararea(df_):\n",
    "    return sqrt_transform_helper(df_, 'GarageArea')\n",
    "transformations.append(trans_sqrt_gararea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_log_openporch(df_):\n",
    "    return log_transform_helper(df_, 'OpenPorchSF')\n",
    "transformations.append(trans_log_openporch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_sqrt(df_):\n",
    "    cols = ['MasVnrArea', 'TotalBsmtSF', 'WoodDeckSF']\n",
    "    for col in cols:\n",
    "        df_ = sqrt_transform_helper(df_, col)\n",
    "    return df_\n",
    "transformations.append(trans_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_delete_numeric(df_):\n",
    "    cols = ['3SsnPorch', 'BsmtFinSF2', 'BsmtFinType2', 'EnclosedPorch', 'LowQualFinSF', \n",
    "            'MiscVal', 'ScreenPorch']\n",
    "    return df_.drop(cols, axis=1)\n",
    "transformations.append(trans_delete_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_del_outliers(df_):\n",
    "    df_.loc[2593, 'GarageYrBlt'] = None\n",
    "    df_.loc[(524, 1299), 'GrLivArea'] = None\n",
    "    df_.loc[1299, 'TotalBsmtSF'] = None\n",
    "    df_.loc[(935, 1299), 'LotFrontage'] = None\n",
    "    df_.loc[496, 'OpenPorchSF'] = None\n",
    "    return df_\n",
    "transformations.append(trans_del_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_quality_to_ordinal(df_):\n",
    "    def convert_ordinal_cat_to_int(df_, col):\n",
    "        df_.loc[df_[col].isnull(), col] = '__missing'\n",
    "        grouped_ordered = df_[[col, COL_Y]].groupby(col).median().sort_values(by=COL_Y)\n",
    "        q_map = {}\n",
    "        for i, key in enumerate(grouped_ordered.index):\n",
    "            q_map[key] = i\n",
    "        df_[col] = df_[col].map(q_map)\n",
    "        return df_\n",
    "    \n",
    "    ordinal_quality_cols = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', \n",
    "                            'BsmtCond', \n",
    "                            'ExterCond',  'ExterQual', 'FireplaceQu', 'Fence',\n",
    "                            'GarageCond', 'GarageFinish', 'GarageQual', 'PavedDrive',\n",
    "                            'HeatingQC', 'KitchenQual',  'Functional'] \n",
    "    for col in ordinal_quality_cols:\n",
    "        df_ = convert_ordinal_cat_to_int(df_, col)\n",
    "        \n",
    "    return df_\n",
    "transformations.append(trans_quality_to_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether transformations actually improve score\n",
    "I don't want to just use intuition for these transformations - they should make sense and actually improve the score. Since we have such a small dataset, we can easily repeat a full grid search CV in a short amount of time.\n",
    "Below, every transformation is applied independently and we compare the performance against the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_cv(df_train, y_train, clf_class, param_grid):\n",
    "    _, params, score = gridcv(df_train, y_train, clf_class(), param_grid, \n",
    "                              n_jobs=1, verbose=False)\n",
    "    return score, params\n",
    "\n",
    "def transformation_effectiveness(df_in, clf_class, param_grid, trans_list):\n",
    "    df_train, y_train, _ = prep_data(df_in, COL_Y, [])\n",
    "    baseline, params = do_cv(df_train, y_train, clf_class, param_grid)\n",
    "    print(\"Baseline: {:.3f}, params: {}\".format(baseline, params))\n",
    " \n",
    "    effective_transformations = []\n",
    "    for trans in trans_list:\n",
    "        df_train, y_train, _ = prep_data(df_in, COL_Y, [trans])\n",
    "        score, params = do_cv(df_train, y_train, clf_class, param_grid)\n",
    "        percentage_diff = (score - baseline) / baseline * 100\n",
    "        \n",
    "        if percentage_diff < 0:\n",
    "            effective_transformations.append(trans)\n",
    "\n",
    "        print(\"{:30s} {:.3f}  {:6.2f}%, params: {}\".format(trans.__name__, score, \n",
    "                                                           percentage_diff, params))\n",
    "    return effective_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.140, params: {'alpha': 5.5}\n",
      "trans_mssubclass               0.139   -0.38%, params: {'alpha': 5}\n",
      "trans_lotshape                 0.139   -0.62%, params: {'alpha': 5}\n",
      "trans_landcontour              0.141    0.50%, params: {'alpha': 5.5}\n",
      "trans_del_utilities            0.140    0.01%, params: {'alpha': 5.5}\n",
      "trans_lotconfig                0.140    0.27%, params: {'alpha': 6.25}\n",
      "trans_landslope                0.140    0.05%, params: {'alpha': 5.5}\n",
      "trans_neighborhood             0.146    4.30%, params: {'alpha': 30}\n",
      "trans_add_is_new               0.140   -0.10%, params: {'alpha': 5.5}\n",
      "trans_add_remodel              0.140    0.09%, params: {'alpha': 6}\n",
      "trans_fix_year_remod_add       0.140    0.00%, params: {'alpha': 5.5}\n",
      "trans_del_yrsold               0.140   -0.01%, params: {'alpha': 5.5}\n",
      "trans_del_mosold               0.140   -0.08%, params: {'alpha': 6}\n",
      "trans_del_roofmatl             0.140    0.13%, params: {'alpha': 7}\n",
      "trans_roof_style               0.140   -0.05%, params: {'alpha': 6}\n",
      "trans_del_miscfeature          0.140   -0.07%, params: {'alpha': 5}\n",
      "trans_condition                0.139   -0.57%, params: {'alpha': 4}\n",
      "trans_exterior                 0.139   -0.38%, params: {'alpha': 5}\n",
      "trans_del_salecondition        0.139   -0.34%, params: {'alpha': 4}\n",
      "trans_del_saletype             0.140    0.07%, params: {'alpha': 6.75}\n",
      "trans_housestyle               0.140   -0.06%, params: {'alpha': 5}\n",
      "trans_masvnrtype               0.140   -0.04%, params: {'alpha': 5}\n",
      "trans_del_elec                 0.140   -0.15%, params: {'alpha': 5.5}\n",
      "trans_foundation               0.140   -0.02%, params: {'alpha': 5}\n",
      "trans_heating                  0.140    0.00%, params: {'alpha': 5.5}\n",
      "trans_log                      0.130   -7.19%, params: {'alpha': 8}\n",
      "trans_sqrt_gararea             0.140   -0.07%, params: {'alpha': 5.5}\n",
      "trans_log_openporch            0.140   -0.24%, params: {'alpha': 5.5}\n",
      "trans_sqrt                     0.136   -2.93%, params: {'alpha': 4}\n",
      "trans_delete_numeric           0.141    1.11%, params: {'alpha': 6.75}\n",
      "trans_del_outliers             0.117  -16.06%, params: {'alpha': 6.25}\n",
      "trans_quality_to_ordinal       0.140    0.26%, params: {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "effective_transformations = transformation_effectiveness(\n",
    "    df_comb, Ridge, {\"alpha\": [1., 1, 2, 3, 4, 5, 5.5, 6, 6.25, 6.5, 6.75, 7, 8, 9, \n",
    "                               10, 11, 12, 13, 14, 15, 20, 25, 30, 35, 40, 45, 50]},\n",
    "    transformations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the results for future reference (it takes some time to execute and the cell contents disappear when experimenting):\n",
    "\n",
    "    Baseline: 0.140, params: {'alpha': 5.5}\n",
    "    trans_mssubclass               0.139   -0.38%, params: {'alpha': 5}\n",
    "    trans_lotshape                 0.139   -0.62%, params: {'alpha': 5}\n",
    "    trans_landcontour              0.141    0.50%, params: {'alpha': 5.5}\n",
    "    trans_del_utilities            0.140    0.01%, params: {'alpha': 5.5}\n",
    "    trans_lotconfig                0.140    0.27%, params: {'alpha': 6.25}\n",
    "    trans_landslope                0.140    0.05%, params: {'alpha': 5.5}\n",
    "    trans_neighborhood             0.146    4.30%, params: {'alpha': 30}\n",
    "    trans_add_is_new               0.140   -0.10%, params: {'alpha': 5.5}\n",
    "    trans_add_remodel              0.140    0.09%, params: {'alpha': 6}\n",
    "    trans_fix_year_remod_add       0.140    0.00%, params: {'alpha': 5.5}\n",
    "    trans_del_yrsold               0.140   -0.01%, params: {'alpha': 5.5}\n",
    "    trans_del_mosold               0.140   -0.08%, params: {'alpha': 6}\n",
    "    trans_del_roofmatl             0.140    0.13%, params: {'alpha': 7}\n",
    "    trans_roof_style               0.140   -0.05%, params: {'alpha': 6}\n",
    "    trans_del_miscfeature          0.140   -0.07%, params: {'alpha': 5}\n",
    "    trans_condition                0.139   -0.57%, params: {'alpha': 4}\n",
    "    trans_exterior                 0.139   -0.38%, params: {'alpha': 5}\n",
    "    trans_del_salecondition        0.139   -0.34%, params: {'alpha': 4}\n",
    "    trans_del_saletype             0.140    0.07%, params: {'alpha': 6.75}\n",
    "    trans_housestyle               0.140   -0.06%, params: {'alpha': 5}\n",
    "    trans_masvnrtype               0.140   -0.04%, params: {'alpha': 5}\n",
    "    trans_del_elec                 0.140   -0.15%, params: {'alpha': 5.5}\n",
    "    trans_foundation               0.140   -0.02%, params: {'alpha': 5}\n",
    "    trans_heating                  0.140    0.00%, params: {'alpha': 5.5}\n",
    "    trans_log                      0.130   -7.19%, params: {'alpha': 8}\n",
    "    trans_sqrt_gararea             0.140   -0.07%, params: {'alpha': 5.5}\n",
    "    trans_log_openporch            0.140   -0.24%, params: {'alpha': 5.5}\n",
    "    trans_sqrt                     0.136   -2.93%, params: {'alpha': 4}\n",
    "    trans_delete_numeric           0.141    1.11%, params: {'alpha': 6.75}\n",
    "    trans_del_outliers             0.117  -16.06%, params: {'alpha': 6.25}\n",
    "    trans_quality_to_ordinal       0.140    0.26%, params: {'alpha': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative percentual difference compared to the baseline performance is a good thing. If it's positive, it means that the transformation didn't really pan out as expected and actually decreased performance.\n",
    "\n",
    "Important lesson learned earlier on: there's way too much variance in the results with Boosted Trees. It can't be used to base decisions on. Ridge regression, on the other hand, is *very* stable. As long as - and this is very important - we do a grid search to find right value for alpha, because this differs a lot depending on how many variables are remaining after applying the transformation.\n",
    "\n",
    "Downside of this approach that we're only basing decisions to include or exclude transformations on just one model (a linear model in this case). The result is that we might make choices to optimize linear models at the expense of Boosted Tree performance. Another blind spot is combinations of transformations. I think this an acceptable risk, and empirically I've found that improvements measured here consistently lead to improvements on the leaderboard with the model ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  2 - apply automatic imputation and conversions\n",
    "\n",
    "`prep_data` is a neat function that takes a DF, makes a local copy, and does the following:\n",
    "\n",
    "1. apply manual transformations\n",
    "2. apply KNN imputer to fill missing data\n",
    "3. apply automatic transformations (i.e. standardization, label encoder, one hot encoding)\n",
    "4. split df into df_train, y_train (a Series), df_test\n",
    "    \n",
    "It then returns the transformed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** Applying manual transformations\n",
      " -> Manual transformation trans_mssubclass\n",
      " -> Manual transformation trans_lotshape\n",
      " -> Manual transformation trans_add_is_new\n",
      " -> Manual transformation trans_del_yrsold\n",
      " -> Manual transformation trans_del_mosold\n",
      " -> Manual transformation trans_roof_style\n",
      " -> Manual transformation trans_del_miscfeature\n",
      " -> Manual transformation trans_condition\n",
      " -> Manual transformation trans_exterior\n",
      " -> Manual transformation trans_del_salecondition\n",
      " -> Manual transformation trans_housestyle\n",
      " -> Manual transformation trans_masvnrtype\n",
      " -> Manual transformation trans_del_elec\n",
      " -> Manual transformation trans_foundation\n",
      " -> Manual transformation trans_log\n",
      " -> Manual transformation trans_sqrt_gararea\n",
      " -> Manual transformation trans_log_openporch\n",
      " -> Manual transformation trans_sqrt\n",
      " -> Manual transformation trans_del_outliers\n",
      "\n",
      " ** Starting knn_impute\n",
      "\n",
      " ** Starting auto-transform\n",
      " -> 74 columns in df before transformations\n",
      " -> Result of automatic column splitting: \n",
      " ---> Numeric/Ordinal: [No further transformation] ['BedroomAbvGr', 'BsmtFullBath', 'BsmtHalfBath', 'CloseToArtery', 'CloseToFeeder', 'ExteriorMaterialCheap', 'ExteriorMaterialExpensive', 'ExteriorMaterialMedium', 'Fireplaces', 'FullBath', 'GarageCars', 'HalfBath', 'IsNew', 'KitchenAbvGr', 'OverallCond', 'OverallQual', 'RegularLotShape', 'TotRmsAbvGrd', 'hasPool']\n",
      " ---> Numerical: [Standardized: mean removal and unit std] ['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'EnclosedPorch', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MasVnrArea', 'MiscVal', 'OpenPorchSF', 'ScreenPorch', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd']\n",
      " ---> Categorical with <= 2 vars [LabelEnc] ['CentralAir', 'RoofStyle', 'Street', 'Utilities']\n",
      " ---> Categorical with > 2 vars [OneHot] ['BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'ExterCond', 'ExterQual', 'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig', 'MSSubClass', 'MSZoning', 'MasVnrType', 'Neighborhood', 'PavedDrive', 'RoofMatl', 'SaleType']\n",
      " -> 215 columns in df after transformations\n",
      "\n",
      " ** Training df has 215 columns and 1460 rows, test df has 215 columns and 1459 rows\n"
     ]
    }
   ],
   "source": [
    "df_train, y_train, df_test = prep_data(df_comb, COL_Y, effective_transformations, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a bunch of models with default parameters\n",
    "\n",
    "*Except for GBR: I added params I found during grid search to get quick feedback on changes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 16:50:28 GradientBoostingRegressor train:  0.078, 10-fold cv:  0.115 (+- 0.010)\n",
      "2017-08-13 16:50:28 Ridge                     train:  0.099, 10-fold cv:  0.125 (+- 0.030)\n",
      "2017-08-13 16:50:28 Lasso                     train:  0.399, 10-fold cv:  0.399 (+- 0.021)\n",
      "2017-08-13 16:50:28 ElasticNet                train:  0.399, 10-fold cv:  0.399 (+- 0.021)\n",
      "2017-08-13 16:50:28 RandomForestRegressor     train:  0.075, 10-fold cv:  0.149 (+- 0.014)\n",
      "2017-08-13 16:50:28 SVR                       train:  0.102, 10-fold cv:  0.121 (+- 0.018)\n"
     ]
    }
   ],
   "source": [
    "models = [GradientBoostingRegressor(**{'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, \n",
    "                                       'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 600, \n",
    "                                       'subsample': 0.7}), \n",
    "          Ridge(),\n",
    "          Lasso(),\n",
    "          ElasticNet(),\n",
    "          RandomForestRegressor(), \n",
    "          SVR(kernel='rbf'),\n",
    "         ]\n",
    "\n",
    "dt_now = datetime.now().replace(microsecond=0)\n",
    "n_folds = 10\n",
    "for model in models:\n",
    "    model.fit(df_train, y_train)\n",
    "    kf_mean, kf_std = calc_kfold_score(model, df_train, y_train, n_splits=n_folds)\n",
    "    print(\"{} {:25s} train: {:6.3f}, {}-fold cv: {:6.3f} (+- {:0.3f})\"\n",
    "          .format(dt_now, model.__class__.__name__, \n",
    "                  rmsle(y_train, model.predict(df_train)), n_folds,\n",
    "                  kf_mean, kf_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how Ridge, Lasso and ElasticNet perform very badly without hyperparameter tuning. I'm doing that in the following cells.\n",
    "\n",
    "Also tried:\n",
    "- SVR with poly or linear kernel... rbf performed better\n",
    "- GaussianProcessRegressor: overfits very badly with default settings. Might not be suitable for such a high dimensionality. Could research this further at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 17:26:00 best score: 0.1170, best params: {'alpha': 4}\n"
     ]
    }
   ],
   "source": [
    "best_ridge, best_ridge_params, _ = gridcv(df_train, y_train, Ridge(), {\n",
    "        \"alpha\": [1., 1, 2, 3, 3.5, 3.75, 4, 4.25, 4.5, 5, 5.5, 6, 6.25, 6.5, 6.75, 7]\n",
    "    }, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 17:26:00 best score: 0.1177, best params: {'C': 2.5, 'epsilon': 0.03, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "best_svr, best_svr_params, _ = gridcv(df_train, y_train, SVR(), {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [2.0, 2.25, 2.5, 2.75, 3.0],\n",
    "        'epsilon': [.001, .03, .01]\n",
    "    }, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 17:01:00 best score: 0.1168, best params: {'alpha': 0.0003}\n"
     ]
    }
   ],
   "source": [
    "best_lasso, best_lasso_params, _ = gridcv(df_train, y_train, Lasso(), {\n",
    "    'alpha': [.0003, .001, .01, .1, .5, 1., 1.1]\n",
    "}, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 17:01:00 best score: 0.1168, best params: {'alpha': 0.0003, 'l1_ratio': 1, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "best_elastic, best_elastic_params, _ = gridcv(df_train, y_train, ElasticNet(), {\n",
    "    'alpha': [.0003, .001, .01, .1, .5, 1., 1.1],\n",
    "    'max_iter': [10000],\n",
    "    'l1_ratio': [0.01, .3, .5, .7, 1]\n",
    "}, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-13 17:22:00 best score: 0.1151, best params: {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 600, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "best_gb, best_gb_params, _ = gridcv(df_train, y_train, GradientBoostingRegressor(), {\n",
    "     #'loss': ['ls', 'lad', 'huber', 'quantile'],   \n",
    "     'loss': ['huber'],  # It always seems to pick 'huber'\n",
    "     'n_estimators': [600, 700, 800], \n",
    "     'max_depth': [2, 3],\n",
    "     'learning_rate': [.01, .1, .2],\n",
    "     'min_samples_split': [2, 3, 4, 5],\n",
    "     'min_samples_leaf': [1, 2],\n",
    "     'subsample': [.6, .7, .8, .9]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# best_xgb, best_xgb_params, _ = gridcv(df_train, y_train, xgb.XGBRegressor(), {\n",
    "#     'max_depth': [2, 3], \n",
    "#     'learning_rate': [.1,], \n",
    "#     'n_estimators': [500, 600, 700],\n",
    "#     'gamma': [0, .01, .1],\n",
    "#     'min_child_weight': [1, 2],\n",
    "#     'subsample': [.7, .8, .9],\n",
    "#     'colsample_bytree': [.7, .8, .9, 1],\n",
    "#     'colsample_bylevel': [.8, .9, 1],\n",
    "#     'reg_alpha': [0, .1],\n",
    "#     'reg_lambda': [1, 1.1, 1.2, 1.5, 2]\n",
    "# }, n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I seem to get a better CV score with sklearn's gradient boost than with XGBoost. I let the code in the cell above run for like 3 hours, very big grid search, but no dice. Of course I can still try more estimators, smaller gamma, different learning rate, lower subsample, but I don't see a reason to use it over sklearn's version to be honest.\n",
    "\n",
    "    2017-08-11 02:29:00 best score: 0.1220, best params: {'colsample_bylevel': 0.8, 'colsample_bytree': 0.7, 'gamma': 0.01, 'learning_rate': 0.1, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 700, 'reg_alpha': 0.1, 'reg_lambda': 1.1, 'subsample': 0.7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = create_submission_from_ensemble(\n",
    "    [best_ridge, best_lasso, best_gb, best_svr], df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze gradient boosting feature importances\n",
    "I used this to fuel investigation in the explorative data analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.061565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.060091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>0.052893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.045391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>0.043195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.042170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>0.039152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.039128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>0.035981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.033507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heating_OthW</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>SaleType_ConLw</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Heating_Grav</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heating_GasA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heating_Floor</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BsmtFinType2_Rec</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>BsmtFinType2_LwQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>BsmtFinType2_GLQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SaleType_Oth</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>ExterCond_TA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cols       imp\n",
       "16          GrLivArea  0.061565\n",
       "31        TotalBsmtSF  0.060091\n",
       "19            LotArea  0.052893\n",
       "26        OverallQual  0.045391\n",
       "13         GarageArea  0.043195\n",
       "0            1stFlrSF  0.042170\n",
       "8           BsmtUnfSF  0.039152\n",
       "4          BsmtFinSF1  0.039128\n",
       "20        LotFrontage  0.035981\n",
       "34          YearBuilt  0.033507\n",
       "99       Heating_OthW  0.000000\n",
       "81     SaleType_ConLw  0.000000\n",
       "98       Heating_Grav  0.000000\n",
       "96       Heating_GasA  0.000000\n",
       "95      Heating_Floor  0.000000\n",
       "93   BsmtFinType2_Rec  0.000000\n",
       "92   BsmtFinType2_LwQ  0.000000\n",
       "91   BsmtFinType2_GLQ  0.000000\n",
       "83       SaleType_Oth  0.000000\n",
       "214      ExterCond_TA  0.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({\"cols\": df_train.columns, \"imp\": best_gb.feature_importances_}) \\\n",
    "        .sort_values(by='imp', ascending=False)\n",
    "pd.concat((imp.head(10), imp.tail(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEWxJREFUeJzt3X+M5HV9x/HncsvdeWa4LGUUm2LPps1bbELVa4BK74cW\nPUAtDU1aYy1RK5r0FFFSQD1/tOWHGqQFLdocveDPmghSgeaKaamXEzVXDG08i28CKTVppVlh71w9\nOTlu+8fMeeOxuzP7mdmZ4ePzkVwy852Zz/f9vp19fT/7mfnOTMzNzSFJevo7btQFSJIGw0CXpEoY\n6JJUCQNdkiphoEtSJSZHufPp6dnit9hMTa1hZubAIMsZiRr6sIfxUUMfNfQAy9tHs9mYmG97T4Ee\nEWcAH8rMzRHxLGA7MAWsAC7MzIci4iLgLcAh4MrMvHMwpc9vcnLFcg4/NDX0YQ/jo4Y+augBRtNH\n1yWXiLgMuAlY3d70YeCzmbkR2AY8PyJOBi4GzgK2ANdExKrlKVmSNJ9e1tAfAi7ouH4W8EsR8c/A\nHwFfAU4H7snMg5m5H3gQOG3AtUqSFtF1ySUzb42IdR2b1gEzmXl2RLwPuBx4ANjfcZ9ZYG23saem\n1vT1Z0mz2Sh+7DipoQ97GB819FFDDzD8PkpeFH0UuL19+Q7gKuBeoLPyBrCv20D9vGDQbDaYnp4t\nfvy4qKEPexgfNfRRQw+wvH0sdKAoedviV4Hz2pc3At8G9gAbImJ1RKwFTgX2FowtSSpUEuiXAhdG\nxNeAc4CrM/MR4AZgN3A38J7MfHxwZUqSuulpySUzHwbObF/+b+Dl89xnO623M0qSRsAzRSWpEga6\nJFVipKf+9+PVl36p+LE7rnjZACuRpPHgDF2SKmGgS1IlDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY\n6JJUCQNdkiphoEtSJQx0SaqEgS5JlTDQJakSBrokVcJAl6RKGOiSVImeAj0izoiIrxyz7bUR8fWO\n6xdFxL0R8Y2IeNWA65QkddE10CPiMuAmYHXHthcBfwJMtK+fDFwMnAVsAa6JiFXLUbAkaX69zNAf\nAi44ciUifgG4Grik4z6nA/dk5sHM3A88CJw2yEIlSYvr+p2imXlrRKwDiIgVwN8B7wR+3HG3E4D9\nHddngbXdxp6aWsPk5Iql1DsQzWZj6PtczLjVU8IexkcNfdTQAwy/j6V+SfR64NeAj9NagnlBRPw1\ncDfQWXkD2NdtsJmZA0vc/WBMT8+OZL/zaTYbY1VPCXsYHzX0UUMPsLx9LHSgWFKgZ+Ye4NcB2rP2\nz2fmJe019KsiYjWwCjgV2NtPwZKkpRnI2xYz8xHgBmA3rdn6ezLz8UGMLUnqTU8z9Mx8GDhzsW2Z\nuR3YPsDaJElL4IlFklQJA12SKmGgS1IlDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY6JJUCQNdkiph\noEtSJQx0SaqEgS5JlTDQJakSBrokVcJAl6RKGOiSVAkDXZIqYaBLUiV6+k7RiDgD+FBmbo6IFwIf\nBZ4EDgIXZub/RcRFwFuAQ8CVmXnnchUtSXqqrjP0iLgMuAlY3d50PfC2zNwMfBG4PCJOBi4GzgK2\nANdExKplqViSNK9eZugPARcAn25ff01mfq/j8Y8DpwP3ZOZB4GBEPAicBvzbYgNPTa1hcnJFUeH9\naDYbQ9/nYsatnhL2MD5q6KOGHmD4fXQN9My8NSLWdVz/HkBEvAR4K7CR1qx8f8fDZoG13caemTmw\nxHIHY3p6diT7nU+z2RirekrYw/iooY8aeoDl7WOhA0XRi6IR8YfAJ4BXZuY08AOgcw8NYF/J2JKk\nMj29KNopIl5H68XPzZn5WHvzHuCqiFgNrAJOBfYOrEpJUldLCvSIWAHcAHwX+GJEAOzKzPdHxA3A\nblqz/vdk5uODLlaStLCeAj0zHwbObF89cYH7bAe2D6YsSdJSeWKRJFXCQJekShjoklQJA12SKmGg\nS1IlDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY6JJUCQNdkiphoEtSJQx0SaqEgS5JlTDQJakSBrok\nVcJAl6RKGOiSVImevlM0Is4APpSZmyPiV4GbgTlgL7A1Mw9HxPuBVwKHgEsyc88y1SxJmkfXGXpE\nXAbcBKxub7oO2JaZG4AJ4PyIeDGwCTgDeA3wN8tTriRpIb3M0B8CLgA+3b6+HtjVvrwTeAWQwJcz\ncw74bkRMRkQzM6cXG3hqag2TkyvKKu9Ds9kY+j4XM271lLCH8VFDHzX0AMPvo2ugZ+atEbGuY9NE\nO7gBZoG1wAnAox33ObJ90UCfmTmwpGIHZXp6diT7nU+z2RirekrYw/iooY8aeoDl7WOhA0XJi6KH\nOy43gH3AD9qXj90uSRqSkkC/LyI2ty+fC+wG7gG2RMRxEfFc4LjM/P6AapQk9aCnd7kc41Jge0Ss\nBO4HbsnMJyNiN/B1WgeJrQOsUZLUg54CPTMfBs5sX36A1jtajr3PB4APDK40SdJSeGKRJFXCQJek\nShjoklQJA12SKmGgS1IlDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY6JJUCQNdkiphoEtSJQx0SaqE\ngS5JlTDQJakSBrokVcJAl6RKlHynKBFxPPBJYB3wJHARcAi4GZgD9gJbM/PwQKqUJHVVOkM/D5jM\nzJcAfwFcBVwHbMvMDcAEcP5gSpQk9aI00B8AJiPiOOAE4AlgPbCrfftO4Oz+y5Mk9apoyQX4Ia3l\nlu8AJwGvAjZm5lz79llgbbdBpqbWMDm5orCEcs1mY+j7XMy41VPCHsZHDX3U0AMMv4/SQH8HcFdm\nvisiTgHuBlZ23N4A9nUbZGbmQOHu+zM9PTuS/c6n2WyMVT0l7GF81NBHDT3A8vax0IGidMllBtjf\nvvwYcDxwX0Rsbm87F9hdOLYkqUDpDP2vgB0RsZvWzPzdwL3A9ohYCdwP3DKYEiVJvSgK9Mz8IfAH\n89y0qb9yJEmlPLFIkiphoEtSJQx0SaqEgS5JlTDQJakSBrokVcJAl6RKGOiSVAkDXZIqYaBLUiUM\ndEmqhIEuSZUw0CWpEga6JFXCQJekShjoklQJA12SKmGgS1IlDHRJqkTpl0QTEe8CfpfWl0TfCOwC\nbgbmgL3A1sw8PIAaJUk9KJqhR8Rm4CXAWbS+GPoU4DpgW2ZuACaA8wdUoySpB6VLLluAbwG3AXcA\ndwLrac3SAXYCZ/ddnSSpZ6VLLicBvwy8CngecDtwXGbOtW+fBdZ2G2Rqag2TkysKSyjXbDaGvs/F\njFs9JexhfNTQRw09wPD7KA30R4HvZOZPgIyIx2ktuxzRAPZ1G2Rm5kDh7vszPT07kv3Op9lsjFU9\nJexhfNTQRw09wPL2sdCBonTJ5avAORExERG/CDwT+Jf22jrAucDuwrElSQWKZuiZeWdEbAT20Doo\nbAX+C9geESuB+4FbBlalJKmr4rctZuZl82ze1EctkqQ+eGKRJFXCQJekShjoklQJA12SKmGgS1Il\nDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY6JJUCQNdkiphoEtSJQx0SaqEgS5JlTDQJakSBrokVcJA\nl6RKGOiSVIni7xQFiIhnAd8EXg4cAm4G5oC9wNbMPNxvgZKk3hTP0CPieOBvgR+3N10HbMvMDcAE\ncH7/5UmSetXPDP1a4BPAu9rX1wO72pd3Aq8AbltsgKmpNUxOruijhDLNZmPo+1zMuNVTwh7GRw19\n1NADDL+PokCPiNcD05l5V0QcCfSJzJxrX54F1nYbZ2bmQMnu+zY9PTuS/c6n2WyMVT0l7GF81NBH\nDT3A8vax0IGidIb+RmAuIs4GXgh8CnhWx+0NYF/h2JKkAkVr6Jm5MTM3ZeZm4N+BC4GdEbG5fZdz\ngd0DqVCS1JO+3uVyjEuB7RGxErgfuGWAY0uSuug70Nuz9CM29TueJKmMJxZJUiUMdEmqhIEuSZUw\n0CWpEga6JFXCQJekShjoklQJA12SKmGgS1IlBnnq/9PGGz94d1+P33HFywZUiSQNjjN0SaqEgS5J\nlTDQJakSBrokVcJAl6RKGOiSVAkDXZIqYaBLUiWKTiyKiOOBHcA6YBVwJfCfwM3AHLAX2JqZhwdS\npSSpq9IZ+uuARzNzA3AO8DHgOmBbe9sEcP5gSpQk9aI00L8AvLd9eQI4BKwHdrW37QTO7q80SdJS\nFC25ZOYPASKiAdwCbAOuzcy59l1mgbXdxpmaWsPk5IqSEkaq2WyM9XijYA/jo4Y+augBht9H8Ydz\nRcQpwG3AjZn5uYj4cMfNDWBftzFmZg6U7n6kpqdnBzZWs9kY6HijYA/jo4Y+augBlrePhQ4URUsu\nEfFs4MvA5Zm5o735vojY3L58LrC7ZGxJUpnSGfq7gSngvRFxZC397cANEbESuJ/WUowkaUhK19Df\nTivAj7Wpv3IkSaU8sUiSKmGgS1IlDHRJqoSBLkmVMNAlqRIGuiRVwkCXpEoY6JJUCQNdkiphoEtS\nJQx0SaqEgS5JlSj+PPSfZ2/84N3Fj91xxcsGWIkkHeUMXZIqYaBLUiVcchkyl2skLRdn6JJUCQNd\nkirhksvTSD/LNf1wqUd6ehhooEfEccCNwG8AB4E3ZeaDg9yH1Kun6+sV/dR9x0fOH8l+fx4P+v1O\nsJbj/2zQM/TfA1Zn5m9FxJnAR4DyZ5jGwjg+cZfbqP4a6terL/3SqEsYOg9ERw16Df23gX8CyMxv\nAL854PElSQuYmJubG9hgEXETcGtm7mxf/y7wK5l5aGA7kSTNa9Az9B8Ajc7xDXNJGo5BB/o9wHkA\n7TX0bw14fEnSAgb9ouhtwMsj4mvABPCGAY8vSVrAQNfQJUmj45miklQJA12SKmGgS1IlxvKzXLp9\nhEBEXAS8BTgEXJmZd0bEScDngGcA/wu8ITMPDL34ozUuuYeO2y4BTs7MK4Zb9VMV/iyeC+yg9fya\nAN6cmTn04o/WWNLDc4DPACuBx4DXZebs0Ivv0OdzahPwmcw8ZbhV/6zCn8WJwAPA3vbdbsvM64db\n+VGFPTwT+DjwPFrPqbdl5p5B1zauM/SffoQAcAWtjxAAICJOBi4GzgK2ANdExCrgfcDnMnMDcB+t\n/9BRWnIPEfGMiPgssHUUBS+g5Gfxl8DHMnMzcDVwzbCLPkZJD5cDn+x4Pr1p6FU/VUkfRMQpwDuB\n44de8VOV9PBi4O8zc3P738jCvK2khz8D9rafTxcBsRyFjWugL/YRAqcD92TmwczcDzwInNb5GGAn\ncPbwyp1XSQ+rgU8CVw251sWU9HEp8I/t+0wCjw+v3HmV9PAO4DPt2dgpwL7hljyvJfcREauBTwB/\nOuxiF1Dys1gPrI+IXRHxhfZfT6NU0sMW4CcRcRfwXuCu5ShsXAP9BGB/x/UnI2JygdtmgbXHbD+y\nbZSW3ENmzmTml4dVYI9K+vh+Zj4REQFcC/z5cEpdUEkPc8AKWn/mvxQYh0/rKvm9+BhwbWb+z3BK\n7Kqkh+8A78vMTcA/AB8dRqGLKOnhJGAqM7cAd9D6vRi4cQ30xT5C4NjbGrRmT53bj2wbpZIexlFR\nHxHxUlq/fH88yvXztqIeMvOJzHwB8GbgU8MotIul9vETYAPw/oj4CnBiRHx+GIUuouRncTfwr+1t\ntwEvWu4iuyjp4VHg9va2O1imDy4c10Bf7CME9gAbImJ1RKwFTqU1i/rpY4Bzgd3DK3deJT2MoyX3\n0Q7z64FzMvPeYRc8j5Iebmz3Aa1Z1uFhFryApfaxJzPjyNoz8FhmvmbYRR+j5PfiJuD32/f5HeCb\nwyt3XiU9fJWj+bQR+PZyFDaWZ4p2vIp8Gkc/QuA84MHMvL39KvKbaR2Qrs7MWyPi2bTWnxvA94HX\nZuaPRtIAZT10PPb1wPPH7F0uS/lZ/AewCnikPUxm5shepC7s4fm01p7naIX5WzPz/pE00NbPc6r9\n+Ecy8+Qhl/0zCn8Wz6P1rqkJ4Ee03lXyvZE0QHEPJ9I6MD0HeAK4MDMfHnRtYxnokqSlG9clF0nS\nEhnoklQJA12SKmGgS1IlDHRJqoSBLkmVMNAlqRL/D13DwfhJ5gJ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c6ea940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(imp['imp'].values, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
